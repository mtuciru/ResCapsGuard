{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch_optimizer\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "import torchaudio\n",
    "from torchmetrics import ROC\n",
    "from torchinfo import summary\n",
    "from torch_optimizer import AdaBound\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "from typing import Union\n",
    "import soundfile as sf\n",
    "import sys\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output, Audio\n",
    "clear_output()\n",
    "\n",
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progressbar(it, prefix=\"\", size=60, out=sys.stdout): # Python3.6+\n",
    "    count = len(it)\n",
    "    start = time.time()\n",
    "    def show(j):\n",
    "        x = int(size*j/count)\n",
    "        remaining = ((time.time() - start) / j) * (count - j)\n",
    "        passing = time.time() - start\n",
    "        mins_pas, sec_pass = divmod(passing, 60)\n",
    "        time_pas = f\"{int(mins_pas):02}:{sec_pass:05.2f}\"\n",
    "        \n",
    "        \n",
    "        mins, sec = divmod(remaining, 60)\n",
    "        time_str = f\"{int(mins):02}:{sec:05.2f}\"\n",
    "        \n",
    "        \n",
    "        print(f\"{prefix}[{u'█'*x}{('.'*(size-x))}] {j}/{count} time {time_pas} / {time_str}\", end='\\r', file=out, flush=True)\n",
    "        \n",
    "    for i, item in enumerate(it):\n",
    "        yield item\n",
    "        show(i+1)\n",
    "    print(\"\\n\", flush=True, file=out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RawNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sinc conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SincConv(nn.Module):\n",
    "    \"\"\"Sinc-based convolution\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : `int`\n",
    "        Number of input channels. Must be 1.\n",
    "    out_channels : `int`\n",
    "        Number of filters.\n",
    "    kernel_size : `int`\n",
    "        Filter length.\n",
    "    sample_rate : `int`, optional\n",
    "        Sample rate. Defaults to 16000.\n",
    "    Usage\n",
    "    -----\n",
    "    See `torch.nn.Conv1d`\n",
    "    Reference\n",
    "    ---------\n",
    "    Mirco Ravanelli, Yoshua Bengio,\n",
    "    \"Speaker Recognition from raw waveform with SincNet\".\n",
    "    https://arxiv.org/abs/1808.00158\n",
    "    \"\"\"\n",
    " \n",
    "    @staticmethod\n",
    "    def to_mel(hz):\n",
    "        return 2595 * np.log10(1 + hz / 700)\n",
    " \n",
    "    @staticmethod\n",
    "    def to_hz(mel):\n",
    "        return 700 * (10 ** (mel / 2595) - 1)\n",
    " \n",
    "    def __init__(self, out_channels, kernel_size, sample_rate=64000, in_channels=1,\n",
    "                 stride=1, padding=0, dilation=1, bias=False, groups=1, min_low_hz=0, min_band_hz=0):\n",
    " \n",
    "        super(SincConv,self).__init__()\n",
    " \n",
    "        if in_channels != 1:\n",
    "            #msg = (f'SincConv only support one input channel '\n",
    "            #       f'(here, in_channels = {in_channels:d}).')\n",
    "            msg = \"SincConv only support one input channel (here, in_channels = {%i})\" % (in_channels)\n",
    "            raise ValueError(msg)\n",
    " \n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    " \n",
    "        # Forcing the filters to be odd (i.e, perfectly symmetrics)\n",
    "        if kernel_size%2==0:\n",
    "            self.kernel_size=self.kernel_size+1\n",
    " \n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    " \n",
    "        if bias:\n",
    "            raise ValueError('SincConv does not support bias.')\n",
    "        if groups > 1:\n",
    "            raise ValueError('SincConv does not support groups.')\n",
    " \n",
    "        self.sample_rate = sample_rate\n",
    "        self.min_low_hz = min_low_hz\n",
    "        self.min_band_hz = min_band_hz\n",
    " \n",
    "        # initialize filterbanks such that they are equally spaced in Mel scale\n",
    "        low_hz = 0\n",
    "        high_hz = self.sample_rate / 2 - (self.min_low_hz + self.min_band_hz)\n",
    " \n",
    "        # In the future we will set high hz as band_hz + low + min_band_hz + min_low_hz\n",
    "        # Where band_hz is (high_hz - low_hz). Therefore, it is reasonable to\n",
    "        # do diff and do not set high_hz as sr/2\n",
    " \n",
    "        mel = np.linspace(self.to_mel(low_hz),\n",
    "                          self.to_mel(high_hz),\n",
    "                          self.out_channels + 1)\n",
    "        hz = self.to_hz(mel)\n",
    " \n",
    " \n",
    "        # filter lower frequency (out_channels, 1)\n",
    "        self.low_hz_ = nn.Parameter(torch.Tensor(hz[:-1]).view(-1, 1)) # learnable f1 from the paper\n",
    " \n",
    "        # filter frequency band (out_channels, 1)\n",
    "        self.band_hz_ = nn.Parameter(torch.Tensor(np.diff(hz)).view(-1, 1)) # learnable f2 (f2 = f1+diff) from the paper\n",
    " \n",
    "        # len(g) = kernel_size\n",
    "        # It is symmetric, therefore we will do computations only with left part, while creating g.\n",
    " \n",
    "        # Hamming window\n",
    "        #self.window_ = torch.hamming_window(self.kernel_size)\n",
    "        n_lin=torch.linspace(0, (self.kernel_size/2)-1, steps=int((self.kernel_size/2))) # computing only half of the window\n",
    "        self.window_=0.54-0.46*torch.cos(2*math.pi*n_lin/self.kernel_size)\n",
    " \n",
    "        # self.window is eq. (8)\n",
    " \n",
    " \n",
    "        # (1, kernel_size/2)\n",
    "        n = (self.kernel_size - 1) / 2.0\n",
    "        self.n_ = 2*math.pi*torch.arange(-n, 0).view(1, -1) / self.sample_rate # Due to symmetry, I only need half of the time axes\n",
    " \n",
    "        # self.n_ = 2 * pi * n / sr\n",
    " \n",
    " \n",
    "    def forward(self, waveforms):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        waveforms : `torch.Tensor` (batch_size, 1, n_samples)\n",
    "            Batch of waveforms.\n",
    "        Returns\n",
    "        -------\n",
    "        features : `torch.Tensor` (batch_size, out_channels, n_samples_out)\n",
    "            Batch of sinc filters activations.\n",
    "        \"\"\"\n",
    " \n",
    "        self.n_ = self.n_.to(waveforms.device)\n",
    " \n",
    "        # print('self.n_', self.n_)\n",
    "        # print('--------------------')\n",
    " \n",
    "        self.window_ = self.window_.to(waveforms.device)\n",
    " \n",
    "        low = self.min_low_hz  + torch.abs(self.low_hz_) # eq. (5) + make sure low >= min_low_hz\n",
    " \n",
    "        high = torch.clamp(low + self.min_band_hz + torch.abs(self.band_hz_),self.min_low_hz,self.sample_rate/2) # eq. (6) + make sure band has length >= min_band_hz\n",
    "        band=(high-low)[:,0] # g[0] / 2\n",
    " \n",
    "        # print('band', band)\n",
    "        # print('low', low)\n",
    "        # print('high', high)\n",
    "        # print('--------------------')\n",
    " \n",
    "        f_times_t_low = torch.matmul(low, self.n_) # 2 * pi * n * freq / sr\n",
    "        f_times_t_high = torch.matmul(high, self.n_)\n",
    " \n",
    "        # print('times_t_low', f_times_t_low)\n",
    "        # print('times_t_high', f_times_t_high)\n",
    "        # print('--------------------')\n",
    " \n",
    "        # 2*f2*sinc(2*pi*f2*n) - 2*f1*sinc(2*pi*f1*n)\n",
    "        # 2*f2*sin(2*pi*f2*n) / (2 * pi * f2 * n) - 2*f1*sin(2*pi*f1*n) / (2 * pi * f1 * n)\n",
    "        # sin(2*pi*f2*n) / (pi n) - sin(2*pi*f1*n) / (pi n)\n",
    " \n",
    "        # (2 / sr) * sin(f_times_t_high) / self.n_ -  (2 / sr) * sin(f_times_t_low) / self.n_\n",
    "        # (1/ sr) * (sin(f_times_t_high) - sin(f_times_t_low)) / (self.n_ / 2)\n",
    " \n",
    "        # sr * correct eq. (4)\n",
    " \n",
    "        # because self.n_ = 2 * pi * n / sr\n",
    " \n",
    "        band_pass_left=((torch.sin(f_times_t_high)-torch.sin(f_times_t_low))/(self.n_/2))*self.window_ # Equivalent of Eq.4 of the reference paper (SPEAKER RECOGNITION FROM RAW WAVEFORM WITH SINCNET). I just have expanded the sinc and simplified the terms. This way I avoid several useless computations.\n",
    "        band_pass_center = 2*band.view(-1,1) # g[0] = 2 * (f2 - f1) = 2 * band, w[0] = 1\n",
    "        band_pass_right= torch.flip(band_pass_left,dims=[1]) # g[n] = g[-n]\n",
    " \n",
    "        # print('band_pass_left', band_pass_left)\n",
    "        # print('band_pass_center', band_pass_center)\n",
    "        # print('---------------')\n",
    " \n",
    " \n",
    "        band_pass=torch.cat([band_pass_left,band_pass_center,band_pass_right],dim=1) # create full g[n]\n",
    " \n",
    " \n",
    "        band_pass = band_pass / (2*band[:,None]) # normalize so the max is 1\n",
    " \n",
    "        # band_pass_left = sr * correct (4)\n",
    "        # center = freq (not scaled via division) = sr * scaled_freq\n",
    "        # thus, after normalization we will divide all by sr and get normalized correct(4) + normalized center\n",
    " \n",
    " \n",
    "        self.filters = (band_pass).view(\n",
    "            self.out_channels, 1, self.kernel_size)\n",
    " \n",
    "        return F.conv1d(waveforms, self.filters, stride=self.stride,\n",
    "                        padding=self.padding, dilation=self.dilation,\n",
    "                         bias=None, groups=1) # x[n] * g[n]\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### res blocK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Res_block(nn.Module):\n",
    "    def __init__(self, nb_filts: int, first=False):\n",
    "        super().__init__()\n",
    "        # for first res block in net\n",
    "        self.first = first\n",
    "\n",
    "        if not self.first:\n",
    "            self.bn1 = nn.BatchNorm2d(num_features=nb_filts[0])\n",
    "            \n",
    "        self.conv1 = nn.Conv2d(in_channels=nb_filts[0],\n",
    "                               out_channels=nb_filts[1],\n",
    "                               kernel_size=(2, 3),\n",
    "                               padding=(1, 1),\n",
    "                               stride=1)\n",
    "        self.selu = nn.SELU(inplace=True)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=nb_filts[1])\n",
    "        self.conv2 = nn.Conv2d(in_channels=nb_filts[1],\n",
    "                               out_channels=nb_filts[1],\n",
    "                               kernel_size=(2, 3),\n",
    "                               padding=(0, 1),\n",
    "                               stride=1)\n",
    "\n",
    "        if nb_filts[0] != nb_filts[1]:\n",
    "            self.downsample = True\n",
    "            self.conv_downsample = nn.Conv2d(in_channels=nb_filts[0],\n",
    "                                             out_channels=nb_filts[1],\n",
    "                                             padding=(0, 1),\n",
    "                                             kernel_size=(1, 3),\n",
    "                                             stride=1)\n",
    "\n",
    "        else:\n",
    "            self.downsample = False\n",
    "            \n",
    "        self.mp = nn.MaxPool2d((1, 3))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # original sample save\n",
    "        original_x = x \n",
    "        \n",
    "        if not self.first:\n",
    "            out = self.bn1(x)\n",
    "            out = self.selu(out)\n",
    "            \n",
    "        else:\n",
    "            out = x\n",
    "            \n",
    "        out = self.conv1(x)\n",
    "        \n",
    "        out = self.bn2(out)\n",
    "        out = self.selu(out)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        # resizing original sample in case of size diff with out\n",
    "        if self.downsample:\n",
    "            original_x = self.conv_downsample(original_x)\n",
    "\n",
    "        # adding original sample in the end of res block\n",
    "        out += original_x\n",
    "        out = self.mp(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_args):\n",
    "        super().__init__()\n",
    "        \n",
    "        # list of some args of original model. Full list: https://github.com/clovaai/aasist/blob/main/config/AASIST.conf\n",
    "        self.d_args = d_args\n",
    "        filts = d_args[\"filts\"]\n",
    "\n",
    "        self.sinc_conv = SincConv(out_channels=filts[0],\n",
    "                                  kernel_size=d_args[\"first_conv\"],\n",
    "        )\n",
    "        \n",
    "        self.first_bn = nn.BatchNorm2d(num_features=1)\n",
    "        self.selu = nn.SELU(inplace=True)\n",
    "\n",
    "        self.res_encoder = nn.Sequential(\n",
    "            Res_block(nb_filts=filts[1], first=True),\n",
    "            Res_block(nb_filts=filts[2]),\n",
    "            Res_block(nb_filts=filts[3]),\n",
    "            Res_block(nb_filts=filts[4]),\n",
    "            Res_block(nb_filts=filts[4]),\n",
    "            Res_block(nb_filts=filts[4])\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        x = self.sinc_conv(x)\n",
    "        x = x.unsqueeze(dim=1)\n",
    "        \n",
    "        x = F.max_pool2d(torch.abs(x), (3, 3))\n",
    "        x = self.first_bn(x)\n",
    "        x = self.selu(x)\n",
    "\n",
    "        \n",
    "        e = self.res_encoder(x) # [batch, filter, spec,sequence]\n",
    "        # print(e.shape)\n",
    "        return e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CapsNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chanelWiseStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChanelWiseStats(nn.Module):\n",
    "    \"\"\"\n",
    "    The class that computes mean and standart deviation\n",
    "    in input data acrocc channels\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(ChanelWiseStats, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.data.shape[0], x.data.shape[1],\n",
    "                   x.data.shape[2]*x.data.shape[3])\n",
    "        \n",
    "        mean = torch.mean(x, 2)\n",
    "        std = torch.std(x,2)\n",
    "        \n",
    "        return torch.stack((mean, std), dim=1)\n",
    "    \n",
    "\n",
    "class View(nn.Module):\n",
    "    \"\"\"\n",
    "    Auxiliary class\n",
    "    \"\"\"\n",
    "    def __init__(self, *shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input.view(self.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primary capsules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryCapsules(nn.Module):\n",
    "    \"\"\"\n",
    "    This class create capsules and makes\n",
    "    forward propagation through them\n",
    "    \"\"\"\n",
    "    def __init__(self, num_capsules=10):\n",
    "        super(PrimaryCapsules, self).__init__()\n",
    "\n",
    "        self.num_capsules = num_capsules\n",
    "\n",
    "        self.capsules = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(64,16, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                ChanelWiseStats(),\n",
    "                nn.Conv1d(2,8, kernel_size=5, stride=2, padding=2),\n",
    "                nn.BatchNorm1d(8),\n",
    "                nn.Conv1d(8, 1, kernel_size=3, stride=1, padding=1),\n",
    "                nn.BatchNorm1d(1),\n",
    "                View(-1, 8)\n",
    "            )\n",
    "            for _ in range(num_capsules)\n",
    "        ])\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        results = [capsule(x) for capsule in self.capsules]\n",
    "        result = torch.stack(results, dim=-1)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Routing mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoutingMechanism(nn.Module):\n",
    "    def __init__(self,\n",
    "                 gpu_id,\n",
    "                 num_input_capsules,\n",
    "                 num_output_capsules,\n",
    "                 data_in,\n",
    "                 data_out,\n",
    "                 num_iterations=2):\n",
    "        super(RoutingMechanism, self).__init__()\n",
    "\n",
    "        self.gpu_id = gpu_id\n",
    "        self.num_iterations = num_iterations\n",
    "        self.route_weights = nn.Parameter(torch.randn(\n",
    "            num_output_capsules, num_input_capsules,\n",
    "            data_out, data_in\n",
    "        ))\n",
    "    \n",
    "    def squash(self, x, dim):\n",
    "        squared_norm = (x ** 2).sum(dim=dim, keepdim=True)\n",
    "        scale = squared_norm / (1 + squared_norm)\n",
    "        return scale * x / (torch.sqrt(squared_norm))\n",
    "    \n",
    "    def forward(self, x, random, dropout, random_size=0.01):\n",
    "        # x[batch, data, in_caps]\n",
    "\n",
    "        x = x.transpose(2, 1)\n",
    "        # x[batch, in_caps, data]\n",
    "\n",
    "        if random:\n",
    "            noise = Variable(random_size * torch.randn(*self.route_weights.size()))\n",
    "            if self.gpu_id >=0:\n",
    "                noise = noise.cuda(self.gpu_id)\n",
    "            route_weights = self.route_weights + noise     #w_ji + rand(size(w_ji))\n",
    "        else:\n",
    "            route_weights = self.route_weights\n",
    "\n",
    "        priors = route_weights[:, None, :, :, :] @ x[None, :, :, :, None]\n",
    "\n",
    "        #route_weights[out_caps, 1,     in_caps, data_out, data_in]\n",
    "        #x            [1,        batch, in_caps, data_in, 1]\n",
    "        #priors       [out_caps, batch, in_caps, data_out, 1]\n",
    "        priors = self.squash(priors.transpose(1, 0), dim=3)  #sqush(w_ij u_i)\n",
    "        # priors[batch, out_caps, in_caps, data_out, 1]\n",
    "\n",
    "        if dropout > 0.0:\n",
    "            drop = Variable(torch.FloatTensor(*priors.size())).bernoulli(1.0-dropout)\n",
    "            if self.gpu_id >= 0:\n",
    "                drop = drop.cuda(self.gpu_id)\n",
    "            priors = priors * drop\n",
    "\n",
    "\n",
    "        logits = Variable(torch.zeros(*priors.size()))       #initialization b_ij = \n",
    "        #logits[batch,out_caps,in_caps, data_out,1]\n",
    "\n",
    "        if self.gpu_id >= 0:\n",
    "            logits = logits.cuda(self.gpu_id)\n",
    "\n",
    "        num_iterations = self.num_iterations\n",
    "\n",
    "        for i in range(num_iterations):                       #for r iterations do\n",
    "            probs = F.softmax(logits, dim=2)                  #a_j = softmax(b_j)\n",
    "            outputs = self.squash((probs*priors).sum(dim=2, keepdim=True), dim=3) #v_j=squash(a_ji * u_ji)\n",
    "\n",
    "            \n",
    "            logits = priors * outputs                         #b_ij = v_j*u_ji\n",
    "        \n",
    "        #outputs[b, out_caps, 1, data_out, 1]\n",
    "        outputs = outputs.squeeze()\n",
    "\n",
    "        if len(outputs.shape) == 3:\n",
    "            outputs = outputs.transpose(2,1).contiguous()\n",
    "        else:\n",
    "            outputs = outputs.unsqueeze_(dim=0).transpose(2,1).contiguous()\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleNet(nn.Module):\n",
    "    # во время оценки отключить рандом и дропаут, модель перевести в эвал\n",
    "    def __init__(self, num_class, gpu_id, d_args, num_capsules=3, num_iterations=3):\n",
    "        super(CapsuleNet, self).__init__()\n",
    "        \n",
    "        self.num_class = num_class\n",
    "        self.extractor = Encoder(d_args)\n",
    "        self.fea_ext = PrimaryCapsules(num_capsules=num_capsules)\n",
    "        self.routing_stats = RoutingMechanism(gpu_id=gpu_id, \n",
    "                                              num_input_capsules=num_capsules, \n",
    "                                              num_output_capsules=2,\n",
    "                                              data_in=8,\n",
    "                                              data_out=4,\n",
    "                                              num_iterations=num_iterations)\n",
    "    \n",
    "    def forward(self, x, random=True, dropout=0.05, random_size=0.01):\n",
    "        z = self.extractor(x)\n",
    "        z = self.fea_ext(z)\n",
    "        z = self.routing_stats(z, random, dropout, random_size=0.01)\n",
    "#         classes = F.softmax(z, dim=-1)\n",
    "        class_ = z.detach()\n",
    "        class_ = class_.mean(dim=1)\n",
    "        return z, class_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capsule Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleLoss(nn.Module):\n",
    "    def __init__(self, gpu_id, weight):\n",
    "        super(CapsuleLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.ce = nn.CrossEntropyLoss(weight=self.weight)\n",
    "\n",
    "        if gpu_id>=0:\n",
    "            self.weight.cuda(gpu_id)\n",
    "            self.ce.cuda(gpu_id)\n",
    "    def forward(self, classes, labels):\n",
    "        loss_t = self.ce(classes[:,0,:], labels)\n",
    "\n",
    "        for i in range(classes.size(1) - 1):\n",
    "            loss_t = loss_t + self.ce(classes[:,i+1,:], labels)\n",
    "\n",
    "        return loss_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASVspoof2019(Dataset):\n",
    "    def __init__(self,IDs,dir_path, labels):\n",
    "        self.IDs = IDs\n",
    "        self.labels = labels\n",
    "        self.dir_path = dir_path\n",
    "        self.cut = 64600\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path_to_flac = f\"{self.dir_path}/flac/{self.IDs[index]}.flac\"\n",
    "        audio, rate = sf.read(path_to_flac)\n",
    "        x_pad = self.pad_random(audio, self.cut)\n",
    "        x_inp = Tensor(x_pad)\n",
    "        return (x_inp, torch.tensor(self.labels[index]), rate)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.IDs)\n",
    "\n",
    "    def pad_random(self, x, max_len=64600):\n",
    "        x_len = x.shape[0]\n",
    "\n",
    "        if x_len >= max_len:\n",
    "            stt = np.random.randint(x_len-max_len)\n",
    "            return x[stt:stt+max_len]\n",
    "\n",
    "        num_repeats = int(max_len / x_len) + 1\n",
    "        padded_x = np.tile(x, (num_repeats))[:max_len]\n",
    "        return padded_x\n",
    "    \n",
    "class ASVspoof2019_dev_eval(Dataset):\n",
    "    def __init__(self,IDs,dir_path, labels):\n",
    "        self.IDs = IDs\n",
    "        self.labels = labels\n",
    "        self.dir_path = dir_path\n",
    "        self.cut = 64600\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path_to_flac = f\"{self.dir_path}/flac/{self.IDs[index]}.flac\"\n",
    "        audio, rate = sf.read(path_to_flac)\n",
    "        x_pad = self.pad_random(audio, self.cut)\n",
    "        x_inp = Tensor(x_pad)\n",
    "        return x_inp, self.IDs[index], torch.tensor(self.labels[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.IDs)\n",
    "\n",
    "    def pad_random(self, x, max_len=64600):\n",
    "        x_len = x.shape[0]\n",
    "\n",
    "        if x_len > max_len:\n",
    "            stt = np.random.randint(x_len-max_len)\n",
    "            return x[stt:stt+max_len]\n",
    "\n",
    "        num_repeats = int(max_len / x_len) + 1\n",
    "        padded_x = np.tile(x, (num_repeats))[:max_len]\n",
    "        return padded_x\n",
    " \n",
    "def get_data_for_dataset(path):\n",
    "    ids_list = []\n",
    "    label_list = []\n",
    "    with open(path,\"r\") as file:\n",
    "        for line in file:\n",
    "            line = line.split()\n",
    "            id, label = line[1], line[-1]\n",
    "            ids_list.append(id)\n",
    "            label = 1 if label == \"bonafide\" else 0\n",
    "            label_list.append(label)\n",
    "    return ids_list, label_list\n",
    "\n",
    "train_label_path = \"LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt\"\n",
    "train_path_flac = \"LA/ASVspoof2019_LA_train\"\n",
    "train_IDs, train_labels = get_data_for_dataset(train_label_path)\n",
    " \n",
    "train_dataset = ASVspoof2019(train_IDs,train_path_flac,train_labels)\n",
    "# train_loader = DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=batch_size,\n",
    "#     shuffle=True,\n",
    "#     num_workers=2\n",
    "# )\n",
    "\n",
    "\n",
    "dev_label_path = \"LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt\"\n",
    "dev_path_flac = \"LA/ASVspoof2019_LA_dev\"\n",
    "dev_IDs, dev_labels = get_data_for_dataset(dev_label_path)\n",
    "\n",
    "dev_dataset = ASVspoof2019_dev_eval(dev_IDs, dev_path_flac, dev_labels)\n",
    "# dev_loader = DataLoader(\n",
    "#     dev_dataset,\n",
    "#     batch_size=batch_size,\n",
    "#     shuffle=False,\n",
    "#     num_workers=2\n",
    "# )\n",
    "\n",
    "\n",
    "eval_label_path = \"LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt\"\n",
    "eval_path_flac = \"LA/ASVspoof2019_LA_eval\"\n",
    "eval_IDs, eval_labels = get_data_for_dataset(eval_label_path)\n",
    "\n",
    "eval_dataset = ASVspoof2019_dev_eval(eval_IDs, eval_path_flac, eval_labels)\n",
    "# eval_loader = DataLoader(\n",
    "#     eval_dataset,\n",
    "#     batch_size=32,\n",
    "#     shuffle = False,\n",
    "#     num_workers =2\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EER & t-DCf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_det_curve(bonafide_scores, spoof_scores):\n",
    "    \"\"\"\n",
    "    function, that comuputes FRR and FAR with their thresholds\n",
    "\n",
    "    args:\n",
    "        bonafide_scores: score for bonafide speech\n",
    "        spoof_scores: score for spoofed speech\n",
    "    output:\n",
    "        frr: false rejection rate\n",
    "        far: false acceptance rate\n",
    "        threshlods: thresholds for frr and far\n",
    "    todo:\n",
    "        rewrite to torch\n",
    "        create tests\n",
    "    \"\"\"\n",
    "    # number of scores\n",
    "    n_scores = bonafide_scores.size + spoof_scores.size\n",
    "\n",
    "    # bona fide scores and spoof scores\n",
    "    all_scores = np.concatenate((bonafide_scores, spoof_scores))\n",
    "\n",
    "    # label of bona fide score is 1\n",
    "    # label of spoof score is 0\n",
    "    labels = np.concatenate((np.ones(bonafide_scores.size), np.zeros(spoof_scores.size)))\n",
    "\n",
    "    # indexes of sorted scores in all scores\n",
    "    indices = np.argsort(all_scores, kind='mergesort')\n",
    "    # sort labels based on scores\n",
    "    labels = labels[indices]\n",
    "\n",
    "    # Compute false rejection and false acceptance rates\n",
    "\n",
    "    # tar cumulative value\n",
    "    tar_trial_sums = np.cumsum(labels)\n",
    "    nontarget_trial_sums = spoof_scores.size - (np.arange(1, n_scores + 1) - tar_trial_sums)\n",
    "\n",
    "    # false rejection rates\n",
    "    frr = np.concatenate((np.atleast_1d(0), tar_trial_sums / bonafide_scores.size)) \n",
    "\n",
    "    # false acceptance rates \n",
    "    far = np.concatenate((np.atleast_1d(1), nontarget_trial_sums / spoof_scores.size))\n",
    "\n",
    "    # Thresholds are the sorted scores\n",
    "    thresholds = np.concatenate((np.atleast_1d(all_scores[indices[0]] - 0.001), all_scores[indices]))  \n",
    "\n",
    "    return frr, far, thresholds\n",
    "\n",
    "\n",
    "def compute_eer(bonafide_scores, spoof_scores):\n",
    "    \"\"\" \n",
    "    Returns equal error rate (EER) and the corresponding threshold.\n",
    "    args:\n",
    "        bonafide_scores: score for bonafide speech\n",
    "        spoof_scores: score for spoofed speech\n",
    "    output:\n",
    "        eer: equal error rate\n",
    "        threshold: index, where frr=far\n",
    "    todo:\n",
    "        rewrite to torch\n",
    "        create tests\n",
    "    \"\"\"\n",
    "    frr, far, thresholds = compute_det_curve(bonafide_scores, spoof_scores)\n",
    "\n",
    "    # absolute differense between frr and far\n",
    "    abs_diffs = np.abs(frr - far)\n",
    "\n",
    "    # index of minimal absolute difference\n",
    "    min_index = np.argmin(abs_diffs)\n",
    "\n",
    "    # equal error rate\n",
    "    eer = np.mean((frr[min_index], far[min_index]))\n",
    "    return eer, thresholds[min_index]\n",
    "\n",
    "def produce_evaluation_file(data_loader,\n",
    "                            model,\n",
    "                            device,\n",
    "                            loss_fn,\n",
    "                            save_path,\n",
    "                            trial_path,\n",
    "                            random = False,\n",
    "                            dropout = 0):\n",
    "    \"\"\"\n",
    "    Create file, that need to give in function calculcate_t-DCF_EER\n",
    "    args:\n",
    "        data_loader: loader, that gives batch to model\n",
    "        model: model, that calculate what we need\n",
    "        device: device for data, model\n",
    "        save_path: path where file shoud be saved\n",
    "        trial_path: path from LA CM protocols\n",
    "    todo:\n",
    "        this function must return result: tensor of uid, src, key, score\n",
    "    \"\"\"\n",
    "\n",
    "    # turning model into evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # read file ASVspoof2019.LA.cm.<dev/train/eval>.trl.txt\n",
    "    with open(trial_path, \"r\") as file_trial:\n",
    "        trial_lines = file_trial.readlines()\n",
    "    \n",
    "    # list of utterance id and list of score for appropiate uid\n",
    "    fname_list = []\n",
    "    score_list = []\n",
    "    current_loss = 0\n",
    "    # inference\n",
    "    for batch_x, utt_id, batch_y in progressbar(data_loader, prefix='computing cm score'):\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # first is hidden layer, second is result\n",
    "            classes, batch_out = model.forward(batch_x, random=random, dropout=dropout)\n",
    "\n",
    "            # 1 - for bonafide speech class\n",
    "            batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n",
    "            loss = loss_fn(classes, batch_y)\n",
    "            current_loss += loss.item() / len(data_loader)\n",
    "\n",
    "        # add outputs\n",
    "        fname_list.extend(utt_id)\n",
    "        score_list.extend(batch_score.tolist())\n",
    "    assert len(trial_lines) == len(fname_list) == len(score_list)\n",
    "\n",
    "    # saving results\n",
    "    with open(save_path, \"w\") as fh:\n",
    "\n",
    "        # fn - uid, sco - score, trl - trial_lines\n",
    "        for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n",
    "\n",
    "            # first - id of speaker\n",
    "            # utt_id - utterance id\n",
    "            # third - \"-\"\n",
    "            # src - type of spoof if exist\n",
    "            # key - spoof or bonafide\n",
    "            _, utt_id, _, src, key = trl.strip().split(' ')\n",
    "            assert fn == utt_id\n",
    "            # format: utterance id - type of spoof attack - key - score\n",
    "            fh.write(\"{} {} {} {}\\n\".format(utt_id, src, key, sco))\n",
    "    print(\"Scores saved to {}\".format(save_path))\n",
    "    \n",
    "    return current_loss\n",
    "    \n",
    "def obtain_asv_error_rates(tar_asv, non_asv, spoof_asv, asv_thresholds):\n",
    "    \"\"\"\n",
    "    Calculate false alarm rate and miss rate for asv scores\n",
    "\n",
    "    args:\n",
    "        tar_asv: scores for asv targets\n",
    "        non_asv: scores for asv nontargets\n",
    "        spoof_asv: scores for asv spoofed\n",
    "        asv_threshold: threshold for asv EER between targets and non_targets\n",
    "    returns:\n",
    "        Pfa_asv: false alarm rate for asv\n",
    "        Pmiss_asv: false miss rate for asv\n",
    "        Pmiss_spoof_asv: rate of rejection spoofs in asv\n",
    "    todo:\n",
    "        rewrite to torch\n",
    "    \"\"\"\n",
    "    Pfa_asv = sum(non_asv >= asv_thresholds) / non_asv.size\n",
    "    Pmiss_asv = sum(tar_asv < asv_thresholds) / tar_asv.size\n",
    "\n",
    "    if spoof_asv.size == 0:\n",
    "        Pmiss_spoof_asv = None\n",
    "    else:\n",
    "        Pmiss_spoof_asv = np.sum(spoof_asv < asv_thresholds) / spoof_asv.size\n",
    "\n",
    "    return Pfa_asv, Pmiss_asv, Pmiss_spoof_asv\n",
    "\n",
    "def compute_tDCF(bonafide_score_cm,spoof_score_cm, Pfa_asv,\n",
    "    Pmiss_asv, Pmiss_spoof_asv, cost_model):\n",
    "    \"\"\"\n",
    "    This function computes min t-DCF value\n",
    "    \n",
    "    args:\n",
    "        bonafide_score_cm: score for bonafide speech from CM system\n",
    "        spoof_score_cm: score for spoofed speech from CM systn\n",
    "        Pfa_asv: false alarm rate from asv system\n",
    "        Pmiss_asv: miss rate from asv sustem\n",
    "        Pmiss_spoof_asv: miss rate for spoof utterance from asv system\n",
    "        cost_model: dict of parameters for t-DCF\n",
    "    output:\n",
    "        t-DCF: computed value\n",
    "        CM_threshold: threshold for EER between Pmiss_cm and Pfa_cm\n",
    "    todo:\n",
    "        rewrite to torch\n",
    "    \"\"\"\n",
    "\n",
    "    # obtain miss and false alarm rate of cm\n",
    "    Pmiss_cm, Pfa_cm, CM_thresholds = compute_det_curve(\n",
    "        bonafide_score_cm, spoof_score_cm\n",
    "    )\n",
    "\n",
    "    # Constants\n",
    "    C1 = cost_model['Ptar'] * (cost_model['Cmiss_cm'] - cost_model['Cmiss_asv'] * Pmiss_asv) - \\\n",
    "        cost_model['Pnon'] * cost_model['Cfa_asv'] * Pfa_asv\n",
    "    \n",
    "    C2 = cost_model['Cfa_cm'] * cost_model['Pspoof'] * (1 - Pmiss_spoof_asv)\n",
    "\n",
    "    # obtain t-DCF curve for all thresholds\n",
    "    tDCF = C1 * Pmiss_cm + C2 * Pfa_cm\n",
    "\n",
    "    # normalized t-DCF\n",
    "    tDCFnorm = tDCF / np.minimum(C1, C2)\n",
    "\n",
    "    return tDCFnorm, CM_thresholds\n",
    "\n",
    "\n",
    "def calculate_eer_tdcf(cm_scores_file, asv_score_file, output_file, printout=True):\n",
    "    \"\"\"\n",
    "    Function cimputes tdcf, eer for CM sustem, and also compute\n",
    "    EER of each type of attack and write them into file\n",
    "    args:\n",
    "        cm_scores_file: file from produce_evaluation file\n",
    "        asv_score_file: file from organizers\n",
    "        ouput_file: file where information of each type of attack for eval dataset will be\n",
    "        printout: print this file or not\n",
    "    output:\n",
    "        EER * 100: percentage of equal error rate for CM system\n",
    "        min_tDCF: value of t-DCF for CM system\n",
    "    todo:\n",
    "        rewrite into torch\n",
    "        return array instead of create file\n",
    "    \"\"\"\n",
    "    # cm data from file\n",
    "    cm_data = np.genfromtxt(cm_scores_file, dtype=str)\n",
    "\n",
    "    # type of spoof attack\n",
    "    cm_sources = cm_data[:,1]\n",
    "\n",
    "    # spoof or bonafide speech\n",
    "    cm_keys = cm_data[:, 2]\n",
    "\n",
    "    # score for utterance\n",
    "    cm_scores = cm_data[:, 3].astype(np.float64)\n",
    "\n",
    "    # score for bonafide speech\n",
    "    bona_cm = cm_scores[cm_keys == 'bonafide']\n",
    "\n",
    "    # score for spoofed utterance\n",
    "    spoof_cm = cm_scores[cm_keys == 'spoof']\n",
    "\n",
    "    # equal error rate\n",
    "    EER, _ = compute_eer(bona_cm, spoof_cm)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # fix parameters for t-DCF\n",
    "    cost_model = {\n",
    "        'Pspoof': 0.05,\n",
    "        'Ptar': 0.9405,\n",
    "        'Pnon': 0.0095,\n",
    "        'Cmiss': 1,\n",
    "        'Cfa': 10, ###########\n",
    "        'Cmiss_asv': 1,\n",
    "        'Cfa_asv': 10,\n",
    "        'Cmiss_cm': 1,\n",
    "        'Cfa_cm' : 10,\n",
    "    }\n",
    "\n",
    "    # load organizers' ASV scores\n",
    "    asv_data = np.genfromtxt(asv_score_file, dtype=str)\n",
    "\n",
    "    # keys: target, non-target, spoof\n",
    "    asv_keys = asv_data[:, 1]\n",
    "\n",
    "    # score for each utterance\n",
    "    asv_scores = asv_data[:, 2].astype(np.float64)\n",
    "\n",
    "\n",
    "    # target, non-target and spoof scores from the ASV scores\n",
    "    tar_asv = asv_scores[asv_keys == 'target']\n",
    "    non_asv = asv_scores[asv_keys == 'nontarget']\n",
    "    spoof_asv = asv_scores[asv_keys == 'spoof']\n",
    "    \n",
    "    #EER of the standalone systems and fix ASV operation point to\n",
    "    eer_asv, asv_threshold = compute_eer(tar_asv, non_asv)\n",
    "\n",
    "    # generate attack types from A07 to A19\n",
    "    attack_types = [f'A{_id:02d}' for _id in range(7,20)]\n",
    "\n",
    "    # compute eer for each type of attack\n",
    "    if printout:\n",
    "        spoof_cm_breakdown = {\n",
    "            attack_type: cm_scores[cm_sources == attack_type]\n",
    "            for attack_type in attack_types\n",
    "        }\n",
    "\n",
    "        eer_cm_breakdown = {\n",
    "            attack_type: compute_eer(bona_cm, spoof_cm_breakdown[attack_type])[0]\n",
    "            for attack_type in attack_types\n",
    "        }\n",
    "    [Pfa_asv, Pmiss_asv, Pmiss_spoof_asv] = obtain_asv_error_rates(\n",
    "        tar_asv,\n",
    "        non_asv,\n",
    "        spoof_asv,\n",
    "        asv_threshold\n",
    "    )\n",
    "\n",
    "    # Compute t-DCF\n",
    "    tDCF_curve, CM_thresholds = compute_tDCF(\n",
    "        bona_cm,\n",
    "        spoof_cm,\n",
    "        Pfa_asv,\n",
    "        Pmiss_asv,\n",
    "        Pmiss_spoof_asv,\n",
    "        cost_model\n",
    "    )\n",
    "\n",
    "    # Minimum t-DCF\n",
    "    min_tDCF_index = np.argmin(tDCF_curve)\n",
    "    min_tDCF = tDCF_curve[min_tDCF_index]\n",
    "    # write results into file\n",
    "    if printout:\n",
    "        with open(output_file, 'w') as f_res:\n",
    "            f_res.write('\\nCM SYSTEM\\n')\n",
    "            f_res.write(\"\"\"\\tEER\\t\\t= {:8.9f} % \n",
    "            (Equal error rate for countermeasure)\\n\"\"\".format(EER*100)\n",
    "            )\n",
    "            f_res.write('\\nTANDEM\\n')\n",
    "            f_res.write('\\tmin-tDCF\\t\\t= {:8.9f}\\n'.format(min_tDCF))\n",
    "            f_res.write('\\nBREAKDOWN CM SYSTEM\\n')\n",
    "            for attack_type in attack_types:\n",
    "                _eer = eer_cm_breakdown[attack_type] * 100\n",
    "                f_res.write(\n",
    "                    f'\\tEER {attack_type}\\t\\t= {_eer:8.9f} % (Equal error rate for {attack_type})\\n'\n",
    "                )\n",
    "        os.system(f\"cat {output_file}\")\n",
    "    return EER * 100, min_tDCF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mslenser0\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:8bs38pzv) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.026 MB of 0.033 MB uploaded\\r'), FloatProgress(value=0.7781200058114195, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dev_eer</td><td>▄▇█▃▃▄▁▄▃▂▂▂▃▂▂▄▁▄▃</td></tr><tr><td>dev_loss</td><td>█▂█▂▂▆▁▁▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>dev_tdcf</td><td>▄█▆▃▃▄▁▅▃▂▂▂▄▃▂▄▁▅▃</td></tr><tr><td>train_loss</td><td>▇█▃▃▅▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dev_eer</td><td>3.76758</td></tr><tr><td>dev_loss</td><td>9.26193</td></tr><tr><td>dev_tdcf</td><td>0.12549</td></tr><tr><td>train_loss</td><td>9.33968</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">auspicious-rooster-1</strong> at: <a href='https://wandb.ai/slenser0/CapsNet/runs/8bs38pzv' target=\"_blank\">https://wandb.ai/slenser0/CapsNet/runs/8bs38pzv</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240223_081814-8bs38pzv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:8bs38pzv). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f5fe5e39d5942ea9b8c39791e391731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112069245427847, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/home/borodin_sam/wandb/run-20240223_105844-aqe0ryu1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/slenser0/CapsNet/runs/aqe0ryu1' target=\"_blank\">resplendent-moon-2</a></strong> to <a href='https://wandb.ai/slenser0/CapsNet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/slenser0/CapsNet' target=\"_blank\">https://wandb.ai/slenser0/CapsNet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/slenser0/CapsNet/runs/aqe0ryu1' target=\"_blank\">https://wandb.ai/slenser0/CapsNet/runs/aqe0ryu1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/slenser0/CapsNet/runs/aqe0ryu1?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fef4860e3b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"CapsNet\",\n",
    "    config = {\n",
    "        'batch_size': 32,\n",
    "        'd_args': {\n",
    "            \"nb_samp\": 64600, \n",
    "            \"first_conv\": 128,\n",
    "            \"filts\": [70, [1, 32], [32, 32], [32, 64], [64, 64]],\n",
    "        },\n",
    "        'num_class': 2,\n",
    "        'gpu_id': 1,\n",
    "        'num_capsules': 30,\n",
    "        'epoches': 40,\n",
    "        'opt': 'AdaBound',\n",
    "        'lr': 0.0001,\n",
    "        'weight_decay': 0.00001,\n",
    "        'random': True,\n",
    "        'dropout': 0.05,\n",
    "        'random_size': 0.01,\n",
    "        'num_iterations': 2,\n",
    "        'gamma': 0.5,\n",
    "        'step_size': 10\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CapsuleNet(num_class=wandb.config['num_class'],\n",
    "                   gpu_id=wandb.config['gpu_id'],\n",
    "                   d_args=wandb.config['d_args'],\n",
    "                   num_capsules=wandb.config['num_capsules'],\n",
    "                   num_iterations=wandb.config['num_iterations']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1606664"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================================================================================================\n",
       "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #                   Mult-Adds                 Trainable\n",
       "==========================================================================================================================================================================\n",
       "CapsuleNet                                    [1, 64600]                [1, 4, 2]                 --                        --                        True\n",
       "├─Encoder: 1-1                                [1, 64600]                [1, 64, 23, 29]           --                        --                        True\n",
       "│    └─SincConv: 2-1                          [1, 1, 64600]             [1, 70, 64472]            140                       --                        True\n",
       "│    └─BatchNorm2d: 2-2                       [1, 1, 23, 21490]         [1, 1, 23, 21490]         2                         2                         True\n",
       "│    └─SELU: 2-3                              [1, 1, 23, 21490]         [1, 1, 23, 21490]         --                        --                        --\n",
       "│    └─Sequential: 2-4                        [1, 1, 23, 21490]         [1, 64, 23, 29]           --                        --                        True\n",
       "│    │    └─Res_block: 3-1                    [1, 1, 23, 21490]         [1, 32, 23, 7163]         6,592                     3,231,408,384             True\n",
       "│    │    └─Res_block: 3-2                    [1, 32, 23, 7163]         [1, 32, 23, 2387]         12,480                    2,079,218,464             True\n",
       "│    │    └─Res_block: 3-3                    [1, 32, 23, 2387]         [1, 64, 23, 795]          43,392                    2,401,207,616             True\n",
       "│    │    └─Res_block: 3-4                    [1, 64, 23, 795]          [1, 64, 23, 265]          49,536                    920,673,856               True\n",
       "│    │    └─Res_block: 3-5                    [1, 64, 23, 265]          [1, 64, 23, 88]           49,536                    306,891,456               True\n",
       "│    │    └─Res_block: 3-6                    [1, 64, 23, 88]           [1, 64, 23, 29]           49,536                    101,911,296               True\n",
       "├─PrimaryCapsules: 1-2                        [1, 64, 23, 29]           [1, 8, 30]                --                        --                        True\n",
       "│    └─ModuleList: 2-5                        --                        --                        --                        --                        True\n",
       "│    │    └─Sequential: 3-7                   [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-8                   [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-9                   [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-10                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-11                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-12                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-13                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-14                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-15                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-16                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-17                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-18                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-19                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-20                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-21                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-22                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-23                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-24                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-25                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-26                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-27                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-28                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-29                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-30                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-31                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-32                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-33                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-34                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-35                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "│    │    └─Sequential: 3-36                  [1, 64, 23, 29]           [1, 8]                    46,451                    30,789,802                True\n",
       "├─RoutingMechanism: 1-3                       [1, 8, 30]                [1, 4, 2]                 1,920                     7,680                     True\n",
       "==========================================================================================================================================================================\n",
       "Total params: 1,606,664\n",
       "Trainable params: 1,606,664\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 9.97\n",
       "==========================================================================================================================================================================\n",
       "Input size (MB): 0.26\n",
       "Forward/backward pass size (MB): 939.40\n",
       "Params size (MB): 6.43\n",
       "Estimated Total Size (MB): 946.08\n",
       "=========================================================================================================================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_args= {\n",
    "            \"nb_samp\": 64600, \n",
    "            \"first_conv\": 128,\n",
    "            \"filts\": [70, [1, 32], [32, 32], [32, 64], [64, 64]],\n",
    "        }\n",
    "\n",
    "model = CapsuleNet(num_class=2,\n",
    "                   gpu_id=-1,\n",
    "                   d_args=d_args,\n",
    "                   num_capsules=30,\n",
    "                   num_iterations=2).to(device)\n",
    "\n",
    "summary(model, (1,64600), mode='train', col_names=(\n",
    "                \"input_size\",\n",
    "                \"output_size\",\n",
    "                \"num_params\",\n",
    "                \"mult_adds\",\n",
    "                \"trainable\",\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(1,1,32).view(-1,32).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb 23 10:59:22 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:4C:00.0 Off |                    0 |\n",
      "| N/A   37C    P0              76W / 400W |  28442MiB / 40960MiB |     13%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM4-40GB          Off | 00000000:88:00.0 Off |                    0 |\n",
      "| N/A   33C    P0              58W / 400W |  28233MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3929"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model\n",
    "del optimizer\n",
    "del loss_fn\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 / 40, best_score 1.8837882093302667 [████████....................................................] 110/794 time 00:57.44 / 05:57.18\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 / 40, best_score 1.492453609745629 [███████.....................................................] 104/794 time 00:54.34 / 06:00.52\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m data, label \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), label\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     47\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 48\u001b[0m classes, class_ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrandom\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdropout\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mrandom_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrandom_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(classes, label)\n\u001b[1;32m     54\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "Cell \u001b[0;32mIn[21], line 19\u001b[0m, in \u001b[0;36mCapsuleNet.forward\u001b[0;34m(self, x, random, dropout, random_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m         z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextractor(x)\n\u001b[1;32m     18\u001b[0m         z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfea_ext(z)\n\u001b[0;32m---> 19\u001b[0m         z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrouting_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#         classes = F.softmax(z, dim=-1)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m         class_ \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 32\u001b[0m, in \u001b[0;36mRoutingMechanism.forward\u001b[0;34m(self, x, random, dropout, random_size)\u001b[0m\n\u001b[1;32m     30\u001b[0m     noise \u001b[38;5;241m=\u001b[39m Variable(random_size \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroute_weights\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_id \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 32\u001b[0m         noise \u001b[38;5;241m=\u001b[39m \u001b[43mnoise\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpu_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     route_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroute_weights \u001b[38;5;241m+\u001b[39m noise     \u001b[38;5;66;03m#w_ji + rand(size(w_ji))\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = wandb.config['batch_size']\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "dev_loader = DataLoader(\n",
    "    dev_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "\n",
    "d_args = wandb.config['d_args']\n",
    "\n",
    "device = 'cuda:1' if torch.cuda.is_available else 'cpu'\n",
    "model = CapsuleNet(num_class=wandb.config['num_class'],\n",
    "                   gpu_id=wandb.config['gpu_id'],\n",
    "                   d_args=d_args,\n",
    "                   num_capsules=wandb.config['num_capsules'],\n",
    "                   num_iterations=wandb.config['num_iterations']).to(device)\n",
    "\n",
    "optimizer = AdaBound(model.parameters(),\n",
    "                     lr=wandb.config['lr'],\n",
    "                     weight_decay=wandb.config['weight_decay'])\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                            step_size=wandb.config['step_size'], \n",
    "                                            gamma=wandb.config['gamma'])\n",
    "\n",
    "loss_fn = CapsuleLoss(gpu_id=wandb.config['gpu_id'], weight=torch.FloatTensor([0.1,0.9]))\n",
    "\n",
    "epoches = wandb.config['epoches']\n",
    "\n",
    "best_score = 2\n",
    "best_state = None\n",
    "\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    # train part\n",
    "    train_loss = 0\n",
    "    prefix = '%s / %s, best_score %s ' % (epoch + 1, epoches, best_score)\n",
    "    for data, label, _ in progressbar(train_loader, prefix=prefix):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        classes, class_ = model.forward(data,\n",
    "                                        random=wandb.config['random'],\n",
    "                                        dropout=wandb.config['dropout'],\n",
    "                                        random_size=wandb.config['random_size'])\n",
    "\n",
    "        loss = loss_fn(classes, label)\n",
    "        train_loss += loss.item() / len(train_loader)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "        \n",
    "    # val_part\n",
    "    dev_loss = produce_evaluation_file(dev_loader, model, device, loss_fn, \"pruduced_file.txt\", dev_label_path)\n",
    "    eer, tdcf = calculate_eer_tdcf('pruduced_file.txt',\n",
    "                              \"LA/ASVspoof2019_LA_asv_scores/ASVspoof2019.LA.asv.dev.gi.trl.scores.txt\",\n",
    "                              None,\n",
    "                              printout=False)\n",
    "\n",
    "    if best_score > eer:\n",
    "        best_score = eer\n",
    "        best_state = deepcopy(model.state_dict())\n",
    "        path = 'best_checkpoint' + str(best_score) + \".pth\"\n",
    "        torch.save(best_state, path)\n",
    "\n",
    "    clear_output()\n",
    "\n",
    "    metrics = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"dev_loss\": dev_loss,\n",
    "        \"dev_eer\": eer,\n",
    "        \"dev_tdcf\": tdcf\n",
    "    }\n",
    "    wandb.log(metrics)\n",
    "\n",
    "wandb.finish()\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 / 40, best_score 1.492453609745629 [████████████████████████████████████████....................] 531/794 time 04:39.65 / 02:18.51\r"
     ]
    }
   ],
   "source": [
    "for epoch in range(26):\n",
    "    # train part\n",
    "    train_loss = 0\n",
    "    prefix = '%s / %s, best_score %s ' % (epoch + 1, epoches, best_score)\n",
    "    for data, label, _ in progressbar(train_loader, prefix=prefix):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        classes, class_ = model.forward(data,\n",
    "                                        random=wandb.config['random'],\n",
    "                                        dropout=wandb.config['dropout'],\n",
    "                                        random_size=wandb.config['random_size'])\n",
    "\n",
    "        loss = loss_fn(classes, label)\n",
    "        train_loss += loss.item() / len(train_loader)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "        \n",
    "    # val_part\n",
    "    dev_loss = produce_evaluation_file(dev_loader, model, device, loss_fn, \"pruduced_file.txt\", dev_label_path)\n",
    "    eer, tdcf = calculate_eer_tdcf('pruduced_file.txt',\n",
    "                              \"LA/ASVspoof2019_LA_asv_scores/ASVspoof2019.LA.asv.dev.gi.trl.scores.txt\",\n",
    "                              None,\n",
    "                              printout=False)\n",
    "\n",
    "    if best_score > eer:\n",
    "        best_score = eer\n",
    "        best_state = deepcopy(model.state_dict())\n",
    "        path = 'best_checkpoint' + str(best_score) + \".pth\"\n",
    "        torch.save(best_state, path)\n",
    "\n",
    "    clear_output()\n",
    "\n",
    "    metrics = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"dev_loss\": dev_loss,\n",
    "        \"dev_eer\": eer,\n",
    "        \"dev_tdcf\": tdcf\n",
    "    }\n",
    "    wandb.log(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_checkpoint1.2491311420651727.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = CapsuleLoss(gpu_id=1, weight=torch.FloatTensor([0.1,0.9])).to('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_label_path = \"LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt\"\n",
    "eval_path_flac = \"LA/ASVspoof2019_LA_eval\"\n",
    "eval_IDs, eval_labels = get_data_for_dataset(eval_label_path)\n",
    "\n",
    "eval_dataset = ASVspoof2019_dev_eval(eval_IDs, eval_path_flac, eval_labels)\n",
    "eval_loader = DataLoader(\n",
    "    eval_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle = False,\n",
    "    num_workers =2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing cm score[████████████████████████████████████████████████████████████] 2227/2227 time 03:31.75 / 00:00.00\n",
      "\n",
      "Scores saved to pruduced_file_eval.txt\n"
     ]
    }
   ],
   "source": [
    "dev_loss = produce_evaluation_file(eval_loader, model, device, loss_fn, \"pruduced_file_eval.txt\", eval_label_path)\n",
    "eer, tdcf = calculate_eer_tdcf('pruduced_file_eval.txt',\n",
    "                              \"LA/ASVspoof2019_LA_asv_scores/ASVspoof2019.LA.asv.eval.gi.trl.scores.txt\",\n",
    "                              None,\n",
    "                              printout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.2701871020649453, 0.07593021271811795)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eer, tdcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
